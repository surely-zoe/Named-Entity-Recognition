{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq75o8qsSnL1",
        "outputId": "de82c955-91ca-477b-83af-6109af25e9a6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zX2x7W7JSt6k"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('train_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3xw8dnkpIOMg",
        "outputId": "96d57f9c-5345-42a7-e370-227208bcae8f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>UTTERANCES</th>\n",
              "      <th>IOB SLOT TAGS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>who plays luke on star wars new hope</td>\n",
              "      <td>O O B_char O B_movie I_movie I_movie I_movie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>show credits for the godfather</td>\n",
              "      <td>O O O B_movie I_movie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>who was the main actor in the exorcist</td>\n",
              "      <td>O O O O O O B_movie I_movie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>find the female actress from the movie she's t...</td>\n",
              "      <td>O O O O O O O B_movie I_movie I_movie I_movie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>who played dory on finding nemo</td>\n",
              "      <td>O O B_char O B_movie I_movie</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID                                         UTTERANCES  \\\n",
              "0   0               who plays luke on star wars new hope   \n",
              "1   1                     show credits for the godfather   \n",
              "2   2             who was the main actor in the exorcist   \n",
              "3   3  find the female actress from the movie she's t...   \n",
              "4   4                    who played dory on finding nemo   \n",
              "\n",
              "                                   IOB SLOT TAGS  \n",
              "0   O O B_char O B_movie I_movie I_movie I_movie  \n",
              "1                          O O O B_movie I_movie  \n",
              "2                    O O O O O O B_movie I_movie  \n",
              "3  O O O O O O O B_movie I_movie I_movie I_movie  \n",
              "4                   O O B_char O B_movie I_movie  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHmQ9VRhSxwJ",
        "outputId": "32fd9ded-d617-424e-dd10-70aded3249ac"
      },
      "outputs": [],
      "source": [
        "data.columns = ['ID', 'input', 'labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1uyWKI27Nxe",
        "outputId": "f35a6d09-837a-43fc-add0-471d478308ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ID                                                   0\n",
              "input             who plays luke on star wars new hope\n",
              "labels    O O B_char O B_movie I_movie I_movie I_movie\n",
              "Name: 0, dtype: object"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "inzuGSB9Eqyb"
      },
      "outputs": [],
      "source": [
        "def split_input(data):\n",
        "    output = []\n",
        "    for i in range(len(data)):\n",
        "      input = data.iloc[i]['input']\n",
        "      labels = data.iloc[i]['labels']\n",
        "      input_list = input.split(\" \")\n",
        "      labels_list = labels.split(\" \")\n",
        "      if len(input_list)!= len(labels_list):\n",
        "        continue\n",
        "      output.append((input_list, labels_list))\n",
        "    return output\n",
        "\n",
        "all_data = split_input(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xLOGbSIrOSJO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'I_cast', 'B_cast', 'B_subject', 'I_director', 'B_genre', 'B_country', 'B_person', 'I_genre', 'O', 'B_language', 'B_char', 'I_char', 'I-movie', 'B_producer', 'I_mpaa_rating', 'B_mpaa_rating', 'I_person', 'I_movie', 'B_location', 'I_country', 'I_release_year', 'I_producer', 'I_language', 'B_director', 'I_subject', 'B_release_year', 'B_movie'}\n",
            "27\n"
          ]
        }
      ],
      "source": [
        "labels = [x[1] for x in all_data]\n",
        "unique_labels = set([item for sublist in labels for item in sublist])\n",
        "\n",
        "print(unique_labels)\n",
        "print(len(unique_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "F2G5wL6uQY7p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def prepare_sequence(seq, to_ix):\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "def word_to_idx(data):\n",
        "    w_dict = {}\n",
        "    for text, label in data:\n",
        "        for word in text:\n",
        "            if word not in w_dict:\n",
        "                w_dict[word] = len(w_dict)\n",
        "    return w_dict\n",
        "\n",
        "def label_to_idx(labels):\n",
        "    l_dict = {}\n",
        "    for idx, label in enumerate(labels):\n",
        "        l_dict[label] = idx\n",
        "    return l_dict    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pBTjyMccRQ_7"
      },
      "outputs": [],
      "source": [
        "word_to_index = word_to_idx(all_data)\n",
        "label_to_index = label_to_idx(unique_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_test = pd.read_csv('test_data.csv')\n",
        "data_test.columns = ['ID', 'input']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_input_test(data):\n",
        "    output = []\n",
        "    for i in range(len(data)):\n",
        "      input = data.iloc[i]['input']\n",
        "      input_list = input.split(\" \")\n",
        "      output.append((input_list))\n",
        "    return output\n",
        "    \n",
        "test_data = split_input_test(data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# update vocab\n",
        "for text in test_data:\n",
        "        for word in text:\n",
        "            if word not in word_to_index:\n",
        "                word_to_index[word] = len(word_to_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class myRNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, output_dim):\n",
        "        super(myRNN, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "        \n",
        "    def forward(self, sentence):\n",
        "        embeddings = self.embeddings(sentence)\n",
        "\n",
        "        rnn_output, hidden = self.rnn(embeddings.view(len(sentence), 1, -1))\n",
        "        \n",
        "        score = F.log_softmax(self.fc(rnn_output.view(len(sentence), -1)), dim=1)\n",
        "        \n",
        "        return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, val_data = train_test_split(all_data, test_size=0.2, random_state=69)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "R_IZjmZnR71z"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "\n",
        "embed_dim = 64\n",
        "hidden_dim = 64\n",
        "\n",
        "my_rnn = myRNN(embed_dim, hidden_dim, len(word_to_index), len(label_to_index))\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.Adam(my_rnn.parameters(), lr=0.001)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FzezNKiASZG9"
      },
      "outputs": [],
      "source": [
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sXhv4cxuSHmq"
      },
      "outputs": [],
      "source": [
        "def train_func(training_data):\n",
        "    my_rnn.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        my_rnn.train()\n",
        "        train_loss = 0.0\n",
        "        for text, label in training_data:\n",
        "            my_rnn.zero_grad()\n",
        "            \n",
        "            input_sentence = prepare_sequence(text, word_to_index)\n",
        "            input_sentence = input_sentence.to(device)\n",
        "\n",
        "            targets = prepare_sequence(label, label_to_index)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            tag_scores = my_rnn(input_sentence)\n",
        "\n",
        "            loss = loss_function(tag_scores, targets)\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            \n",
        "        print('Training loss: ', (train_loss/len(training_data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "LVNHw79p6Hac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss:  0.8790209114401147\n",
            "Training loss:  0.3925950536130011\n",
            "Training loss:  0.2526272682777959\n",
            "Training loss:  0.17488529658142465\n",
            "Training loss:  0.1238094436763654\n",
            "Training loss:  0.09067300626338692\n",
            "Training loss:  0.06862343872638461\n",
            "Training loss:  0.056923023102178574\n",
            "Training loss:  0.048615219359148025\n",
            "Training loss:  0.04260647532446274\n",
            "Training loss:  0.037840300829996704\n",
            "Training loss:  0.03337463187706784\n",
            "Training loss:  0.03177672836982078\n",
            "Training loss:  0.031130641928134167\n",
            "Training loss:  0.028470795618132472\n",
            "Training loss:  0.026794783963932697\n",
            "Training loss:  0.025830966847667627\n",
            "Training loss:  0.02689362830190015\n",
            "Training loss:  0.024247856972061083\n",
            "Training loss:  0.022752538463858503\n",
            "Training loss:  0.023747960575094044\n",
            "Training loss:  0.02286595752062894\n",
            "Training loss:  0.022105558740689653\n",
            "Training loss:  0.022511497536909\n",
            "Training loss:  0.022883285509003686\n",
            "Training loss:  0.02308952137284272\n",
            "Training loss:  0.020184105498665356\n",
            "Training loss:  0.021551086792781324\n",
            "Training loss:  0.021037804366177425\n",
            "Training loss:  0.020893731893884545\n"
          ]
        }
      ],
      "source": [
        "train_func(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fix_labels(labels):\n",
        "    new_labels = []\n",
        "    for i in range(len(labels)):\n",
        "      curr_label = labels[i]\n",
        "      new_label = curr_label.replace(\"_\", \"-\")\n",
        "      new_labels.append(new_label)\n",
        "    return new_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "grhGEz4FC_h3"
      },
      "outputs": [],
      "source": [
        "from seqeval.metrics import classification_report\n",
        "\n",
        "def evaluate_func(dataset):\n",
        "    my_rnn.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    for i in range(len(dataset)):\n",
        "      my_rnn.eval()\n",
        "\n",
        "      inputs = prepare_sequence(val_data[i][0], word_to_index)\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      scores = my_rnn(inputs)\n",
        "\n",
        "      index_to_label = dict((v, k) for k, v in label_to_index.items())\n",
        "\n",
        "      preds = [torch.max(x, 0)[1].item() for x in scores]\n",
        "      correct = prepare_sequence(val_data[i][1], label_to_index)\n",
        "\n",
        "      original_sentence = val_data[i][0]\n",
        "      correct_labels = [index_to_label[c.item()] for c in correct]\n",
        "      predicted_labels = [index_to_label[p] for p in preds]\n",
        "\n",
        "      correct_labels = fix_labels(correct_labels)\n",
        "      predicted_labels = fix_labels(predicted_labels)\n",
        "\n",
        "      all_predictions.append(predicted_labels)\n",
        "      all_targets.append(correct_labels)\n",
        "\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_targets = np.array(all_targets)\n",
        "    # print(all_predictions.shape)\n",
        "    # print(all_targets.shape)\n",
        "    # print(all_predictions[0])\n",
        "    # print(all_targets[0])\n",
        "    \n",
        "    print(classification_report(all_targets, all_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7b9J17DDtsF",
        "outputId": "ae659e7d-e8c6-4771-b8cf-798a8ca8d180"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        cast       0.41      0.65      0.50        17\n",
            "        char       1.00      0.40      0.57         5\n",
            "     country       0.84      0.66      0.74        32\n",
            "    director       0.40      0.61      0.49        28\n",
            "       genre       0.83      0.67      0.74        15\n",
            "    language       0.67      0.82      0.73        22\n",
            "    location       0.00      0.00      0.00         1\n",
            "       movie       0.63      0.79      0.70       197\n",
            " mpaa-rating       1.00      0.85      0.92        26\n",
            "      person       0.58      0.60      0.59        42\n",
            "    producer       0.74      0.70      0.72        40\n",
            "release-year       0.00      0.00      0.00         1\n",
            "     subject       0.79      0.83      0.81        18\n",
            "\n",
            "   micro avg       0.64      0.73      0.68       444\n",
            "   macro avg       0.61      0.58      0.58       444\n",
            "weighted avg       0.67      0.73      0.69       444\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Zoe\\AppData\\Local\\Temp\\ipykernel_25020\\3785628605.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  all_predictions = np.array(all_predictions)\n",
            "C:\\Users\\Zoe\\AppData\\Local\\Temp\\ipykernel_25020\\3785628605.py:33: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  all_targets = np.array(all_targets)\n",
            "c:\\Users\\Zoe\\anaconda3\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "evaluate_func(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RMTonuxSTmDe"
      },
      "outputs": [],
      "source": [
        "data_test = pd.read_csv('test_data.csv')\n",
        "data_test.columns = ['ID', 'input']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_input_test(data):\n",
        "    output = []\n",
        "    for i in range(len(data)):\n",
        "      input = data.iloc[i]['input']\n",
        "      input_list = input.split(\" \")\n",
        "      output.append((input_list))\n",
        "    return output\n",
        "    \n",
        "test_data = split_input_test(data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1SXFF9NfHeEt"
      },
      "outputs": [],
      "source": [
        "def get_predictions_tag(model, test_data):\n",
        "    all_predictions = []\n",
        "    for i in range(len(test_data)):\n",
        "      inputs = prepare_sequence(test_data[i], word_to_index)\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      scores = my_rnn(inputs)\n",
        "\n",
        "      ix_to_tag = dict((v, k) for k, v in label_to_index.items())\n",
        "\n",
        "      preds = [torch.max(x, 0)[1].item() for x in scores]\n",
        "      \n",
        "      predicted_labels = [ix_to_tag[p] for p in preds]\n",
        "\n",
        "\n",
        "      all_predictions.append(predicted_labels)\n",
        "   \n",
        "    all_predictions = np.array(all_predictions)\n",
        "    return all_predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNKqOzofq4zp",
        "outputId": "f21959bc-27e4-4707-f147-000d0801a97e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Zoe\\AppData\\Local\\Temp\\ipykernel_25020\\3421852957.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  all_predictions = np.array(all_predictions)\n"
          ]
        }
      ],
      "source": [
        "test_preds = get_predictions_tag(my_rnn, test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "pbKmf09PrG4b"
      },
      "outputs": [],
      "source": [
        "sub_rnn = data_test[['ID']]\n",
        "sub_rnn['IOB Slot tags'] = test_preds\n",
        "sub_rnn['IOB Slot tags'] = sub_rnn['IOB Slot tags'].apply(lambda x: \" \".join(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5AalQjDgrR_F",
        "outputId": "bdf64f0b-5d4f-4799-8052-b20f6fae2dbb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>IOB Slot tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>B_movie O B_movie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>O O O O O B_movie I_movie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>O O O O O O B_movie I_movie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>O O O B_movie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>O O O B_movie</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID                IOB Slot tags\n",
              "0   0            B_movie O B_movie\n",
              "1   1    O O O O O B_movie I_movie\n",
              "2   2  O O O O O O B_movie I_movie\n",
              "3   3                O O O B_movie\n",
              "4   4                O O O B_movie"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub_rnn.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "BzKbKtKNrc9L"
      },
      "outputs": [],
      "source": [
        "sub_rnn.to_csv('submission_rnn.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "c3437ece83d9be1a611a10f7642590578caefda86989dbeb196251210a92674a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
